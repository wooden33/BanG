# Panta: Hybrid Program Analysis-Guided Test Generation

## Project Structure
    .
    ├── defects4j-subjects-notests/       # defects4j projects without exisiting test suites
    ├── evaluation/                       # scripts and data for evaluation
    │   ├── defects4j-sample/             # sample generated tests by GPT-4o and Llama3-3 discussed in Motivation
    │   ├── defects4j-codefiles/          # static analysis data for each defects4j project     
    │   ├── data/                         # statistics and evaluation results      
    │   └── *.py                          # evaluation scripts
    ├── result-files/                     # result reports generated by Panta for different LLMs and prompts    
    ├── src/
    │   └── panta/                        # Panta implementation
    ├── pyproject.toml                    # configuration file for Panta setup
    ├── panta-env.yml                     # snapshot for panta's conda env setup
    ├── .gitignore   
    └── README.md    

## Instructions to run Panta


### Environment setup
Create the environment using the following command:
```
conda create --name panta-env python=3.11
conda activate panta-env
```

Execute the following command to the project related dependencies:
```
poetry install
```

##### Export the dependencies to a file
```
conda env export --no-builds | grep -v "^prefix: " > panta-env.yml
```

Please update the `pyproject.toml` file with the latest dependencies, if you have added or modified any new dependencies. 

### Configuration: Select LLM Model, Source File, and Parameters

Choose your targeted _llm model_, _src file_, etc. The configrations can be filled in `config.ini` under `src/panta`

We support various LLMs. The full list of supported models is provided below:
- gpt-4o
- gpt-4o-mini
- llama3-3
- llama3-1
- claude3-5
- mistral-large


### Running the application
We use AWS Bedrock for open-source models (llama and mistral), you will need to set up your own aws credentials.

For proprietary models, you need to have your own API Key ready.

Using OPENAI models as an example, to run Panta,  execute the following command:

```
export OPENAI_API_KEY='OPENAI_API_KEY'
poetry run panta
```
You can also run through 
```commandline
python -m panta.main
```


## Instructions to replicate the evaluation is under `evaluation/README.md`
